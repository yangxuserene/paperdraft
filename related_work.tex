\section{Related Work}
\label{sec:related_work}

There are many tools available for system monitoring and application profiling. 
Tools like TAU (Tuning and Analysis)~\cite{tau} and mpiP~\cite{mpip} can capture 
application's runtime information and keep records in event traces. 
However, recognizing the patterns about application's communication from those traces requires substantial effort. There are a number of studies on the recognition and characterization of parallel application communication patterns. Oak Ridge National Laboratory has its ongoing project about developing a tool set named Oxbow, which can characterize the computation and communication behavior of scientific applications and benchmarks~\cite{oxbow}. In a recent work~\cite{roth}, the authors demonstrate a new approach to automatically characterizing parallel applications' communication behaviors. 

%\textbf{P2: communication characteristics}\\

Many research efforts have been conducted to characterize scientific applications. For instance, a DOE project aims at the identification of the computational characteristics of the DOE MiniApps developed at various exascale co-design centers \cite{designforwardwebpage}. In this project, the communication patterns of several DOE full applications and associated mini-applications are studied to provide a more complete snapshot of the DOE workload. A joint project named CORAL from Oak Ridge, Argonne and Livermore provide a series of benchmarks to represent DOE workloads and technical requirements \cite{coral}. The CORAL project includes scalable science benchmarks, throughput benchmarks, data centric benchmarks, skeleton benchmarks and Micro benchmarks.  

%\textbf{P3: Interference between concurrently running jobs}\\
The interference between concurrently running jobs on HPC system have been identified as major culprit for job's performance variability. Abhinav et al. found that concurrently running applications on HPC can cause interference to each other, and cause communication time varied from 36\% faster to 69\% slower. Such interference could come from Operating System noise, shape of the allocated partition , or other running jobs that sharing network resources \cite{abhinav-sc13}. Skinner et al. found that  there is a 2-3$\times$ slowdown in MPI$\textunderscore$Allreduce due to network contention from other jobs \cite{skinner}. Rosenthal et al. found increasing network bandwidth provide limited benefits to a number of applications. The applications that send mostly small messages or large messages asynchronously are not bandwidth bounded, hence, benefit only slightly or not at all from increased bandwidth \cite{rosenthal}.

%\textbf{P4: Job allocation(little bit)}\\
Several research studies focus on optimizing job allocation on HPC system to alleviate the interference between concurrently running jobs. Hoefler et al. proposed to use performance modeling techniques to analyze factors that impact the performance of parallel scientific applications \cite{hoefler-modeling}. However, as the scale of HPC continue to grow, the interference of concurrently running jobs is getting worse, which is hard to be quantified by performance profiling tools alone. Bogdan et al. provide a set of guidelines of how to configure a network with Dragonfly topology for workload with Nearest Neighbor communication pattern \cite{Bogdan-hpdc14}. Dong et al. have developed simple benchmarks that conforms to four different communication patterns, namely ping-pong, nearest neighbor, broadcast and all$\textunderscore$reduce, to demonstrate the effectiveness of this highly parallel 5D torus network \cite{Dong-SC11}.

Our work is different from all these works in the following ways. First, we focus on the dominant communication patterns rather than any specific application. We believe this can provide a guideline for other research work. Secondly, we explore the intra- and inter-job interference between concurrently running jobs, while similar work such as \cite{abhinav-sc13} only focuses on the single application's performance degradation due to network contention. Finally, we analyze the impact of different allocation strategies to job's communication behaviors. We further identify the optimal allocation strategy for each application with a specific dominant communication pattern. Based on our study, we claim that further scheduling should take job's communication pattern into consideration for its allocation decision making. 

